{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2432854,"sourceType":"datasetVersion","datasetId":1472191}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install datasets --quiet\n!pip install evaluate --quiet","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-02T05:17:35.626033Z","iopub.execute_input":"2025-04-02T05:17:35.626368Z","iopub.status.idle":"2025-04-02T05:17:43.197809Z","shell.execute_reply.started":"2025-04-02T05:17:35.626336Z","shell.execute_reply":"2025-04-02T05:17:43.196784Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T05:17:43.199069Z","iopub.execute_input":"2025-04-02T05:17:43.199470Z","iopub.status.idle":"2025-04-02T05:17:43.566685Z","shell.execute_reply.started":"2025-04-02T05:17:43.199436Z","shell.execute_reply":"2025-04-02T05:17:43.566032Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import torch  \nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.utils.data as data \nimport math\nimport copy\n\nfilepath = '/kaggle/working/'\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T05:17:43.567437Z","iopub.execute_input":"2025-04-02T05:17:43.567852Z","iopub.status.idle":"2025-04-02T05:17:44.913770Z","shell.execute_reply.started":"2025-04-02T05:17:43.567828Z","shell.execute_reply":"2025-04-02T05:17:44.913019Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"import kagglehub\n\npath = kagglehub.dataset_download(\"hungnm/englishvietnamese-translation\")\n\nprint(\"Path to dataset files:\", path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T05:17:44.914644Z","iopub.execute_input":"2025-04-02T05:17:44.915177Z","iopub.status.idle":"2025-04-02T05:17:45.354567Z","shell.execute_reply.started":"2025-04-02T05:17:44.915143Z","shell.execute_reply":"2025-04-02T05:17:45.353762Z"}},"outputs":[{"name":"stdout","text":"Path to dataset files: /kaggle/input/englishvietnamese-translation\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import os\nimport pandas as pd\nfrom datasets import Dataset\n\ndata_path = '/kaggle/input/englishvietnamese-translation/'\n\nwith open(os.path.join(data_path, 'en_sents'), 'r') as f:\n    en_sents = f.readlines()\n\nwith open(os.path.join(data_path, 'vi_sents'), 'r') as f:\n    vi_sents = f.readlines()\n\nen_sents = [sent.strip() for sent in en_sents]\nvi_sents = [sent.strip() for sent in vi_sents]\n\ndata_df = pd.DataFrame({\n    'en': en_sents,\n    'vi': vi_sents\n})\nprint(data_df.head())\ndata= Dataset.from_pandas(data_df)\n\nprint(data)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T05:17:45.356525Z","iopub.execute_input":"2025-04-02T05:17:45.356740Z","iopub.status.idle":"2025-04-02T05:17:46.279601Z","shell.execute_reply.started":"2025-04-02T05:17:45.356721Z","shell.execute_reply":"2025-04-02T05:17:46.278690Z"}},"outputs":[{"name":"stdout","text":"                                                  en  \\\n0         Please put the dustpan in the broom closet   \n1                             Be quiet for a moment.   \n2                                          Read this   \n3  Tom persuaded the store manager to give him ba...   \n4        Friendship consists of mutual understanding   \n\n                                                  vi  \n0      xin vui lòng đặt người quét rác trong tủ chổi  \n1                                    im lặng một lát  \n2                                            đọc này  \n3  tom thuyết phục người quản lý cửa hàng trả lại...  \n4             tình bạn bao gồm sự hiểu biết lẫn nhau  \nDataset({\n    features: ['en', 'vi'],\n    num_rows: 254090\n})\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"from datasets import Dataset, DatasetDict\n\n# Split the dataset into train, validation, and test sets (e.g., 80% train, 10% validation, 10% test)\ntrain_data, temp_data = data.train_test_split(test_size=0.2).values()  \nvalid_data, test_data = temp_data.train_test_split(test_size=0.5).values()  \n\nsplit_data = DatasetDict({\n    'train': train_data,\n    'validation': valid_data,\n    'test': test_data\n})\n\n# Check the splits\nprint(f\"Train data: {len(split_data['train'])}\")\nprint(f\"Validation data: {len(split_data['validation'])}\")\nprint(f\"Test data: {len(split_data['test'])}\")\n\nprint(\"Train data example:\", split_data['train'][0])\nprint(\"Validation data example:\", split_data['validation'][0])\nprint(\"Test data example:\", split_data['test'][0])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T05:17:46.281228Z","iopub.execute_input":"2025-04-02T05:17:46.281618Z","iopub.status.idle":"2025-04-02T05:17:46.362931Z","shell.execute_reply.started":"2025-04-02T05:17:46.281594Z","shell.execute_reply":"2025-04-02T05:17:46.362286Z"}},"outputs":[{"name":"stdout","text":"Train data: 203272\nValidation data: 25409\nTest data: 25409\nTrain data example: {'en': 'He feels a good deal better than yesterday', 'vi': 'anh ấy cảm thấy một thỏa thuận tốt hơn so với ngày hôm qua'}\nValidation data example: {'en': 'Your arms and legs have grown strong enough', 'vi': 'cánh tay và chân của bạn đã phát triển đủ mạnh'}\nTest data example: {'en': 'You should just talk to Tom.', 'vi': 'bạn chỉ nên nói chuyện với tom.'}\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"SOURCE_LANG = 'en'\nTARGET_LANG = 'vi'\n\nUNK_IDX, PAD_IDX, SOS_IDX, EOS_IDX = 0, 1, 2, 3 \nSPECIAL_SYMBOLS = ['<unk>', '<pad>', '<sos>', '<eos>']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T05:17:46.363624Z","iopub.execute_input":"2025-04-02T05:17:46.363845Z","iopub.status.idle":"2025-04-02T05:17:46.367566Z","shell.execute_reply.started":"2025-04-02T05:17:46.363811Z","shell.execute_reply":"2025-04-02T05:17:46.366812Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"pip install torch==2.3.0 torchtext==0.18.0\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T05:17:46.368431Z","iopub.execute_input":"2025-04-02T05:17:46.368715Z","iopub.status.idle":"2025-04-02T05:17:49.781036Z","shell.execute_reply.started":"2025-04-02T05:17:46.368685Z","shell.execute_reply":"2025-04-02T05:17:49.779914Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch==2.3.0 in /usr/local/lib/python3.10/dist-packages (2.3.0)\nRequirement already satisfied: torchtext==0.18.0 in /usr/local/lib/python3.10/dist-packages (0.18.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (4.12.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (1.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (2024.12.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (2.20.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (12.1.105)\nRequirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (2.3.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.18.0) (4.67.1)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.18.0) (2.32.3)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.18.0) (1.26.4)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0) (12.6.85)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.3.0) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->torchtext==0.18.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->torchtext==0.18.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->torchtext==0.18.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->torchtext==0.18.0) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->torchtext==0.18.0) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->torchtext==0.18.0) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.18.0) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.18.0) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.18.0) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.18.0) (2025.1.31)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.3.0) (1.3.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torchtext==0.18.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torchtext==0.18.0) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->torchtext==0.18.0) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->torchtext==0.18.0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->torchtext==0.18.0) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import torch\nimport torchtext\n\nprint(torch.__version__)\nprint(torchtext.__version__)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T05:17:49.782262Z","iopub.execute_input":"2025-04-02T05:17:49.782547Z","iopub.status.idle":"2025-04-02T05:17:49.804696Z","shell.execute_reply.started":"2025-04-02T05:17:49.782523Z","shell.execute_reply":"2025-04-02T05:17:49.803833Z"}},"outputs":[{"name":"stdout","text":"2.3.0+cu121\n0.18.0+cpu\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"\nfrom torchtext.data.utils import get_tokenizer\nfrom torchtext.vocab import build_vocab_from_iterator\n\ntoken_transform = {}\nvocab = {}\n\ntoken_transform[SOURCE_LANG] = get_tokenizer('basic_english')\ntoken_transform[TARGET_LANG] = get_tokenizer('basic_english')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T05:17:49.805585Z","iopub.execute_input":"2025-04-02T05:17:49.805873Z","iopub.status.idle":"2025-04-02T05:17:49.816533Z","shell.execute_reply.started":"2025-04-02T05:17:49.805843Z","shell.execute_reply":"2025-04-02T05:17:49.815674Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torchtext/data/__init__.py:4: UserWarning: \n/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \nTorchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n/usr/local/lib/python3.10/dist-packages/torchtext/vocab/__init__.py:4: UserWarning: \n/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \nTorchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n/usr/local/lib/python3.10/dist-packages/torchtext/utils.py:4: UserWarning: \n/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \nTorchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"token_transform['en'](\"hello it's me\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T05:17:49.817417Z","iopub.execute_input":"2025-04-02T05:17:49.817711Z","iopub.status.idle":"2025-04-02T05:17:49.826397Z","shell.execute_reply.started":"2025-04-02T05:17:49.817681Z","shell.execute_reply":"2025-04-02T05:17:49.825592Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"['hello', 'it', \"'\", 's', 'me']"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"def tokenize_example(example, sos_token, eos_token, token_transform, src_lang, tgt_lang):\n    en_tokens = token_transform['en'](example['en'])\n    vi_tokens = token_transform['vi'](example['vi'])\n\n    en_tokens = ([sos_token] + en_tokens + [eos_token])\n    vi_tokens = ([sos_token] + vi_tokens + [eos_token])\n\n    return {\"en_tokens\": (en_tokens), \"vi_tokens\":(vi_tokens)}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T05:17:49.827261Z","iopub.execute_input":"2025-04-02T05:17:49.827639Z","iopub.status.idle":"2025-04-02T05:17:49.840974Z","shell.execute_reply.started":"2025-04-02T05:17:49.827610Z","shell.execute_reply":"2025-04-02T05:17:49.840184Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"fn_kwargs = {\n    'sos_token': '<sos>',\n    'eos_token': '<eos>',\n    'token_transform': token_transform,\n    'src_lang': SOURCE_LANG,\n    'tgt_lang': TARGET_LANG,\n    }\ntrain_data = train_data.map(tokenize_example, fn_kwargs = fn_kwargs)\ntest_data = test_data.map(tokenize_example, fn_kwargs = fn_kwargs)\nvalid_data = valid_data.map(tokenize_example, fn_kwargs = fn_kwargs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T05:17:49.841868Z","iopub.execute_input":"2025-04-02T05:17:49.842199Z","iopub.status.idle":"2025-04-02T05:18:20.838861Z","shell.execute_reply.started":"2025-04-02T05:17:49.842163Z","shell.execute_reply":"2025-04-02T05:18:20.837902Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/203272 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ae4b1d38e7041b4ae57f5fac144e2eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/25409 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5de3e7672e61454dafa2ddbc7bfc87e5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/25409 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d2dd8349d9248bfad076c8eefe3a200"}},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"print(train_data[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T05:18:20.839890Z","iopub.execute_input":"2025-04-02T05:18:20.840163Z","iopub.status.idle":"2025-04-02T05:18:20.844791Z","shell.execute_reply.started":"2025-04-02T05:18:20.840136Z","shell.execute_reply":"2025-04-02T05:18:20.843880Z"}},"outputs":[{"name":"stdout","text":"{'en': 'He feels a good deal better than yesterday', 'vi': 'anh ấy cảm thấy một thỏa thuận tốt hơn so với ngày hôm qua', 'en_tokens': ['<sos>', 'he', 'feels', 'a', 'good', 'deal', 'better', 'than', 'yesterday', '<eos>'], 'vi_tokens': ['<sos>', 'anh', 'ấy', 'cảm', 'thấy', 'một', 'thỏa', 'thuận', 'tốt', 'hơn', 'so', 'với', 'ngày', 'hôm', 'qua', '<eos>']}\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"\nfor lang in [SOURCE_LANG, TARGET_LANG]:\n    vocab[lang] = build_vocab_from_iterator(\n        train_data[lang + '_tokens'],\n        min_freq = 1,\n        specials = SPECIAL_SYMBOLS,\n        special_first = True    # Special tokens get indices 0,1,2,3\n    )\n    vocab[lang].set_default_index(UNK_IDX) # # Default index for OOV words","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T05:18:20.845658Z","iopub.execute_input":"2025-04-02T05:18:20.845937Z","iopub.status.idle":"2025-04-02T05:18:27.137750Z","shell.execute_reply.started":"2025-04-02T05:18:20.845903Z","shell.execute_reply":"2025-04-02T05:18:27.137074Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"\nprint(vocab['vi'].get_itos()[:10])\nprint(len(vocab['vi']))\nprint(vocab['en'].get_itos()[:10])\nprint(len(vocab['en']))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T05:18:27.138536Z","iopub.execute_input":"2025-04-02T05:18:27.138755Z","iopub.status.idle":"2025-04-02T05:18:27.147658Z","shell.execute_reply.started":"2025-04-02T05:18:27.138736Z","shell.execute_reply":"2025-04-02T05:18:27.146781Z"}},"outputs":[{"name":"stdout","text":"['<unk>', '<pad>', '<sos>', '<eos>', 'tôi', '.', 'bạn', 'không', 'tom', 'có']\n6594\n['<unk>', '<pad>', '<sos>', '<eos>', '.', \"'\", 'i', 'the', 'to', 'tom']\n19294\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"\ndef numericalize_example(example, vocab, src_lang, tgt_lang):\n    en_ids = torch.tensor(vocab[src_lang].lookup_indices(example['en_tokens']))\n    vi_ids = torch.tensor(vocab[tgt_lang].lookup_indices(example['vi_tokens']))\n\n    return {'en_ids': en_ids, 'vi_ids': vi_ids}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T05:18:27.148432Z","iopub.execute_input":"2025-04-02T05:18:27.148647Z","iopub.status.idle":"2025-04-02T05:18:27.164351Z","shell.execute_reply.started":"2025-04-02T05:18:27.148627Z","shell.execute_reply":"2025-04-02T05:18:27.163630Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"fn_kwargs = {\n    'vocab': vocab,\n    'src_lang': SOURCE_LANG,\n    'tgt_lang': TARGET_LANG,\n    }\ntrain_data = train_data.map(numericalize_example, fn_kwargs = fn_kwargs)\ntest_data = test_data.map(numericalize_example, fn_kwargs = fn_kwargs)\nvalid_data = valid_data.map(numericalize_example, fn_kwargs = fn_kwargs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T05:18:27.165094Z","iopub.execute_input":"2025-04-02T05:18:27.165345Z","iopub.status.idle":"2025-04-02T05:19:08.883313Z","shell.execute_reply.started":"2025-04-02T05:18:27.165325Z","shell.execute_reply":"2025-04-02T05:19:08.882210Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/203272 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90118ea8228346dcb78d2d53195ef115"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/25409 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f2acf0c32e74d26bd1271fe23f9458c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/25409 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b15e298a976c48ebb53af9c0e00290ca"}},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"train_data[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T05:19:08.887020Z","iopub.execute_input":"2025-04-02T05:19:08.887267Z","iopub.status.idle":"2025-04-02T05:19:08.893161Z","shell.execute_reply.started":"2025-04-02T05:19:08.887247Z","shell.execute_reply":"2025-04-02T05:19:08.892425Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"{'en': 'He feels a good deal better than yesterday',\n 'vi': 'anh ấy cảm thấy một thỏa thuận tốt hơn so với ngày hôm qua',\n 'en_tokens': ['<sos>',\n  'he',\n  'feels',\n  'a',\n  'good',\n  'deal',\n  'better',\n  'than',\n  'yesterday',\n  '<eos>'],\n 'vi_tokens': ['<sos>',\n  'anh',\n  'ấy',\n  'cảm',\n  'thấy',\n  'một',\n  'thỏa',\n  'thuận',\n  'tốt',\n  'hơn',\n  'so',\n  'với',\n  'ngày',\n  'hôm',\n  'qua',\n  '<eos>'],\n 'en_ids': [2, 15, 1138, 11, 85, 489, 154, 109, 207, 3],\n 'vi_ids': [2, 12, 16, 108, 55, 10, 906, 812, 70, 69, 693, 21, 67, 130, 87, 3]}"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"\ndef collate_fn(batch):\n    source_batch = [torch.tensor(sample[SOURCE_LANG + \"_ids\"]) for sample in batch]\n    target_batch = [torch.tensor(sample[TARGET_LANG + \"_ids\"]) for sample in batch]\n\n    source_batch = nn.utils.rnn.pad_sequence(source_batch, padding_value = PAD_IDX, batch_first = True)\n    target_batch = nn.utils.rnn.pad_sequence(target_batch, padding_value = PAD_IDX, batch_first = True)\n    return source_batch, target_batch ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T05:19:08.894991Z","iopub.execute_input":"2025-04-02T05:19:08.895228Z","iopub.status.idle":"2025-04-02T05:19:08.910481Z","shell.execute_reply.started":"2025-04-02T05:19:08.895209Z","shell.execute_reply":"2025-04-02T05:19:08.909746Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nBATCH_SIZE = 16\ntrain_data_loader = torch.utils.data.DataLoader(\n    dataset = train_data,\n    batch_size = BATCH_SIZE,\n    collate_fn = collate_fn,\n    shuffle = True\n)\n\ntest_data_loader = DataLoader(\n    dataset = test_data,\n    batch_size = BATCH_SIZE,\n    collate_fn = collate_fn,\n)\n\nvalid_data_loader = DataLoader(\n    dataset = valid_data,\n    batch_size = BATCH_SIZE,\n    collate_fn = collate_fn,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T05:19:08.911258Z","iopub.execute_input":"2025-04-02T05:19:08.911450Z","iopub.status.idle":"2025-04-02T05:19:08.925440Z","shell.execute_reply.started":"2025-04-02T05:19:08.911433Z","shell.execute_reply":"2025-04-02T05:19:08.924693Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"\nclass MultiHeadAttention(nn.Module):\n\n    def __init__(self, attention_head, model_dimension):\n        super(MultiHeadAttention, self).__init__()\n        assert model_dimension % attention_head == 0, \"dimension of model must be divisible by the attention head\"\n\n        self.attention_head = attention_head\n        self.model_dimension = model_dimension\n        self.d_k = self.model_dimension // self.attention_head\n\n        self.W_q = nn.Linear(model_dimension, model_dimension, bias = False) # Query transformation\n        self.W_k = nn.Linear(model_dimension, model_dimension, bias = False) # Key transformation\n        self.W_v = nn.Linear(model_dimension, model_dimension, bias = False) # Value transformation\n        self.W_o = nn.Linear(model_dimension, model_dimension) # Output transformation\n\n    def scaled_dot_products(self, Q, K, V, mask = None):\n\n        \n        attention_score = (Q @ K.transpose(-2, -1)) / math.sqrt(self.d_k)\n        \n        if mask is not None:\n            mask = mask.unsqueeze(1)\n            attention_score = attention_score.masked_fill(mask == 0, value = -1e9)\n\n        # Attention_probability is computed via softmax function\n        attention_probability = torch.softmax(attention_score, dim = -1)\n\n        output = (attention_probability @ V)\n        return output\n\n\n    def split_heads(self, X):\n\n        batch_size, seq_len, model_dimension = X.shape\n        output = X.view(batch_size, seq_len, self.attention_head, self.d_k)\n        output = output.transpose(1, 2)\n        return output\n\n\n    def combine_heads(self, X):\n        batch_size, _, seq_len, d_k = X.shape\n        output = X.transpose(1, 2).contiguous().view(batch_size, seq_len, self.model_dimension)\n        return output\n\n    def forward(self, Q, K, V, mask = None):\n        Q = self.split_heads(self.W_q(Q))\n        K = self.split_heads(self.W_k(K))\n        V = self.split_heads(self.W_v(V))\n        attention_output = self.scaled_dot_products(Q, K, V, mask)\n\n        output = self.W_o(self.combine_heads(attention_output))  #to mix information from all heads.\n        return output ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T05:19:08.926099Z","iopub.execute_input":"2025-04-02T05:19:08.926366Z","iopub.status.idle":"2025-04-02T05:19:08.940571Z","shell.execute_reply.started":"2025-04-02T05:19:08.926345Z","shell.execute_reply":"2025-04-02T05:19:08.939791Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"class PositionWiseFeedForwardNetwork(nn.Module):\n    def __init__(self, model_dimension, feed_forward_dimension):\n\n        super(PositionWiseFeedForwardNetwork, self).__init__()\n        self.model_dimension = model_dimension\n        self.feed_forward_dimension = feed_forward_dimension\n\n        self.fc1 = nn.Linear(model_dimension, feed_forward_dimension)\n        self.fc2 = nn.Linear(feed_forward_dimension, model_dimension)\n        self.relu = nn.ReLU()\n\n    def forward(self, X):\n        return self.fc2(self.relu(self.fc1(X)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T05:19:08.941253Z","iopub.execute_input":"2025-04-02T05:19:08.941516Z","iopub.status.idle":"2025-04-02T05:19:08.958793Z","shell.execute_reply.started":"2025-04-02T05:19:08.941490Z","shell.execute_reply":"2025-04-02T05:19:08.958174Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"\nclass PositionalEncoding(nn.Module):\n    def __init__(self, model_dimension, max_seq_len, dropout):\n        super(PositionalEncoding, self).__init__()\n        self.model_dimension = model_dimension\n        self.max_seq_len = max_seq_len\n        self.dropout = nn.Dropout(dropout)\n        positional_encoding = torch.zeros(max_seq_len, model_dimension)\n        # Each row will store the position info for one word position.\n\n        position = torch.arange(0, max_seq_len, dtype = torch.float).unsqueeze(1)\n\n        # Creates numbers [0, 1, 2, ..., max_seq_len-1] for word positions.\n\n        # position has shape (max_seq_len, 1)\n        # positional_encoding has shape (max_seq_len, model_dimension)\n        div_term = torch.exp(torch.arange(0, model_dimension, 2).float() * -(math.log(10000.0) / model_dimension))\n#Even indices (0,2,4...): Sine waves.\n\n# Odd indices (1,3,5...): Cosine waves.\n\n# Result: Each dimension gets a unique wavelength, capturing position information\n\n        positional_encoding[:, 0::2] = torch.sin(position * div_term)\n        positional_encoding[:, 1::2] = torch.cos(position * div_term)\n        #Uses mathematical waves to encode positions\n\n        positional_encoding = positional_encoding.unsqueeze(0)\n        \n        self.register_buffer('pe', positional_encoding) #Not updated during backpropagation\n\n\n    def forward(self, X):\n        return self.dropout(X + (self.pe[:, :X.shape[1], :]))\n    \n\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T05:19:08.959683Z","iopub.execute_input":"2025-04-02T05:19:08.959963Z","iopub.status.idle":"2025-04-02T05:19:08.976849Z","shell.execute_reply.started":"2025-04-02T05:19:08.959934Z","shell.execute_reply":"2025-04-02T05:19:08.976177Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"class EncoderBlock(nn.Module):\n    def __init__(self, model_dimension, attention_heads, feed_forward_dimension, dropout):\n        super(EncoderBlock, self).__init__()\n\n        self.attention = MultiHeadAttention(attention_heads, model_dimension)\n        self.feed_forward_network = PositionWiseFeedForwardNetwork(model_dimension, feed_forward_dimension)\n        self.norm1 = nn.LayerNorm(model_dimension)\n        self.norm2 = nn.LayerNorm(model_dimension)\n\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, X, mask):\n        # X is a tensor of shape (batch_size, seq_len, model_dimmension)\n        attention_output = self.attention(X, X, X, mask)\n        X = self.norm1(X + self.dropout(attention_output))\n        feed_forward_output = self.feed_forward_network(X)\n        X = self.norm2(X + self.dropout(feed_forward_output))\n\n        # Return tensor is the same size\n        return X\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T05:19:08.977772Z","iopub.execute_input":"2025-04-02T05:19:08.978073Z","iopub.status.idle":"2025-04-02T05:19:08.992127Z","shell.execute_reply.started":"2025-04-02T05:19:08.978042Z","shell.execute_reply":"2025-04-02T05:19:08.991503Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"class DecoderBlock(nn.Module):\n    def __init__(self, model_dimension, attention_heads, feed_forward_dimension, dropout):\n        super(DecoderBlock, self).__init__()\n\n        self.attention = MultiHeadAttention(attention_heads, model_dimension)\n        self.feed_forward_network = PositionWiseFeedForwardNetwork(model_dimension, feed_forward_dimension)\n        self.norm1 = nn.LayerNorm(model_dimension)\n        self.norm2 = nn.LayerNorm(model_dimension)\n        self.norm3 = nn.LayerNorm(model_dimension)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, X, encoder_output, source_mask, target_mask):\n\n        attention_output = self.attention(X, X, X, target_mask)\n        X = self.norm1(X + self.dropout(attention_output))\n \n        attention_output = self.attention(X, encoder_output, encoder_output, source_mask)\n        \n        X = self.norm2(X + self.dropout(attention_output))\n            \n        feed_forward_output = self.feed_forward_network(X)\n        X = self.norm3(X + self.dropout(feed_forward_output))\n\n        return X","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T05:19:08.993058Z","iopub.execute_input":"2025-04-02T05:19:08.993383Z","iopub.status.idle":"2025-04-02T05:19:09.011119Z","shell.execute_reply.started":"2025-04-02T05:19:08.993352Z","shell.execute_reply":"2025-04-02T05:19:09.010463Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"class Transformer(nn.Module):\n    def __init__(self, model_dimension, attention_heads, feed_forward_dimension,\n                 source_vocab_size, target_vocab_size, num_layers, max_seq_len, dropout):\n        super(Transformer, self).__init__()\n\n        self.model_dimension = model_dimension\n        self.attention_heads = attention_heads\n        self.feed_forward_dimension = feed_forward_dimension\n\n        self.positional_encoding = PositionalEncoding(model_dimension, max_seq_len, dropout)\n        #Maps source token IDs to embeddings of size model_dimension\n        self.encoder_embedding = nn.Embedding(source_vocab_size, model_dimension)\n        #Maps target token IDs to embeddings of size model_dimension\n        self.decoder_embedding = nn.Embedding(target_vocab_size, model_dimension)\n        self.encoders = nn.ModuleList([EncoderBlock(model_dimension, attention_heads, feed_forward_dimension, dropout) for _ in range(num_layers)])\n        self.decoders = nn.ModuleList([DecoderBlock(model_dimension, attention_heads, feed_forward_dimension, dropout) for _ in range(num_layers)])\n        self.dropout = nn.Dropout(dropout)\n        #Final projection layer to target_vocab_size (for predicting output tokens).\n        self.fc = nn.Linear(model_dimension, target_vocab_size)\n    \n    \n    def generate_mask(self, source_sentence, target_sentence):\n#   SRC-> (batch_size, src_seq_len)\n#TARGET -> (batch_size, tgt_seq_len)\n\n        batch_size = source_sentence.shape[0]\n        max_target_len = target_sentence.shape[1]\n\n        #zero out attention scores for padding tokens before softmax.\n        source_mask = (source_sentence != PAD_IDX).unsqueeze(1).int().to(device)\n        \n        # target_mask has shape (batch_size, 1, max_tgt_len)\n        #HANDLE VARIABLE LENGTHS\n        target_mask = (target_sentence != PAD_IDX).unsqueeze(1).int().to(device)\n\n        #Look-Ahead Mask: Upper triangular matrix (0 for future tokens, 1 for past/current).\n        no_peak_mask = 1 - torch.triu(torch.ones((1, max_target_len, max_target_len)), diagonal=1).type(torch.int).to(device)\n\n        target_mask = target_mask & no_peak_mask\n\n        return source_mask, target_mask\n\n    def forward(self, source_sentence, target_sentence):\n\n        source_mask, target_mask = self.generate_mask(source_sentence, target_sentence)\n        #Maps source token IDs to embeddings of size model_dimension,ADD POS ENCODING AND DROPOUT\n        source_embedded = self.dropout(self.positional_encoding(self.encoder_embedding(source_sentence)))\n        target_embedded = self.dropout(self.positional_encoding(self.decoder_embedding(target_sentence)))\n\n        encoder_output = source_embedded\n        for encoder_layer in self.encoders:\n            encoder_output = encoder_layer(encoder_output, source_mask)\n        \n        decoder_output = target_embedded\n        for decoder_layer in self.decoders:\n            decoder_output = decoder_layer(decoder_output, encoder_output, source_mask, target_mask)\n\n        output = self.fc(decoder_output)\n        return output ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T05:19:09.011807Z","iopub.execute_input":"2025-04-02T05:19:09.012006Z","iopub.status.idle":"2025-04-02T05:19:09.026418Z","shell.execute_reply.started":"2025-04-02T05:19:09.011988Z","shell.execute_reply":"2025-04-02T05:19:09.025761Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"model_dimension = 512 #Dimensionality of token embeddings and model outputs\nattention_heads = 8\nfeed_forward_dimension = 2048\nsource_vocab_size = len(vocab[SOURCE_LANG])\ntarget_vocab_size = len(vocab[TARGET_LANG])\nnum_layers = 6\nmax_seq_len = 1000\ndropout = 0.1\n\n\nmodel = Transformer(\n    model_dimension,\n    attention_heads,\n    feed_forward_dimension,\n    source_vocab_size,\n    target_vocab_size,\n    num_layers,\n    max_seq_len,\n    dropout,\n)\n\nmodel= nn.DataParallel(model) #Enables parallel training across multiple GPUs\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T05:19:09.027084Z","iopub.execute_input":"2025-04-02T05:19:09.027329Z","iopub.status.idle":"2025-04-02T05:19:09.749293Z","shell.execute_reply.started":"2025-04-02T05:19:09.027310Z","shell.execute_reply":"2025-04-02T05:19:09.748481Z"}},"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"DataParallel(\n  (module): Transformer(\n    (positional_encoding): PositionalEncoding(\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder_embedding): Embedding(19294, 512)\n    (decoder_embedding): Embedding(6594, 512)\n    (encoders): ModuleList(\n      (0-5): 6 x EncoderBlock(\n        (attention): MultiHeadAttention(\n          (W_q): Linear(in_features=512, out_features=512, bias=False)\n          (W_k): Linear(in_features=512, out_features=512, bias=False)\n          (W_v): Linear(in_features=512, out_features=512, bias=False)\n          (W_o): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (feed_forward_network): PositionWiseFeedForwardNetwork(\n          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n          (relu): ReLU()\n        )\n        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n    )\n    (decoders): ModuleList(\n      (0-5): 6 x DecoderBlock(\n        (attention): MultiHeadAttention(\n          (W_q): Linear(in_features=512, out_features=512, bias=False)\n          (W_k): Linear(in_features=512, out_features=512, bias=False)\n          (W_v): Linear(in_features=512, out_features=512, bias=False)\n          (W_o): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (feed_forward_network): PositionWiseFeedForwardNetwork(\n          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n          (relu): ReLU()\n        )\n        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n    )\n    (dropout): Dropout(p=0.1, inplace=False)\n    (fc): Linear(in_features=512, out_features=6594, bias=True)\n  )\n)"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"def count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\nprint(f\"The model has {count_parameters(model):,} trainable parameters\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T05:19:09.749961Z","iopub.execute_input":"2025-04-02T05:19:09.750190Z","iopub.status.idle":"2025-04-02T05:19:09.755530Z","shell.execute_reply.started":"2025-04-02T05:19:09.750172Z","shell.execute_reply":"2025-04-02T05:19:09.754643Z"}},"outputs":[{"name":"stdout","text":"The model has 54,453,698 trainable parameters\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"optimizer = optim.Adam(model.parameters(), lr = 1e-4)\ncriterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T05:19:09.756380Z","iopub.execute_input":"2025-04-02T05:19:09.756638Z","iopub.status.idle":"2025-04-02T05:19:10.703762Z","shell.execute_reply.started":"2025-04-02T05:19:09.756609Z","shell.execute_reply":"2025-04-02T05:19:10.702998Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"def train_fn(model, data_loader, optimizer, criterion, clip, device):\n    model.train()\n    epoch_loss = 0\n    for i, batch in enumerate(data_loader):\n        \n        source_sentence = batch[0].to(device)\n        target_sentence = batch[1].to(device)\n\n        batch_size = source_sentence.shape[0]\n        target_len = target_sentence.shape[1]\n\n        target_input = target_sentence[:, :-1] \n        target_output = target_sentence[:, 1:] \n\n        optimizer.zero_grad()\n\n        output = model(source_sentence, target_input)\n        output = output.reshape(batch_size * (target_len - 1), output.shape[-1])\n        target_output = target_output.reshape(batch_size * (target_len - 1))\n        loss = criterion(output, target_output)\n        \n        if i % (len(data_loader) // 10) == 0:\n            print(i // (len(data_loader) // 10), \"%\", end = ' ') \n        \n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), clip) #Prevents exploding gradients \n        optimizer.step() #Updates model weights \n        epoch_loss += loss.item()\n        \n    print()\n    return epoch_loss / len(data_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T05:19:10.704625Z","iopub.execute_input":"2025-04-02T05:19:10.705194Z","iopub.status.idle":"2025-04-02T05:19:10.713642Z","shell.execute_reply.started":"2025-04-02T05:19:10.705154Z","shell.execute_reply":"2025-04-02T05:19:10.712236Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"def evaluate_fn(model, data_loader, criterion, device):\n    model.eval()\n    epoch_loss = 0\n    with torch.no_grad():\n        for i, batch in enumerate(data_loader):\n            source_sentence = batch[0].to(device)\n            target_sentence = batch[1].to(device)\n\n            # source_sentence has shape (batch_size, max_src_len)\n            # target_sentence has shape (batch_size, max_tgt_len)\n            \n            batch_size = source_sentence.shape[0]\n            target_len = target_sentence.shape[1]\n            target_input = target_sentence[:, :-1]\n            target_output = target_sentence[:, 1:]\n            \n            output = model(source_sentence, target_input)\n            output = output.reshape(batch_size * (target_len - 1), output.shape[-1])\n            target_output = target_output.reshape(batch_size * (target_len - 1))\n            \n            loss = criterion(output, target_output)\n            epoch_loss += loss.item()\n    return epoch_loss / len(data_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T05:19:10.714686Z","iopub.execute_input":"2025-04-02T05:19:10.714983Z","iopub.status.idle":"2025-04-02T05:19:10.735015Z","shell.execute_reply.started":"2025-04-02T05:19:10.714940Z","shell.execute_reply":"2025-04-02T05:19:10.734159Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"import tqdm\n\nn_epochs = 3\nclip = 1\nbest_valid_loss = float(\"inf\")\nfor epoch in tqdm.tqdm(range(n_epochs)):\n    train_loss = train_fn(model, train_data_loader, optimizer, criterion, clip, device)\n    valid_loss = evaluate_fn(model, valid_data_loader, criterion, device)\n    if valid_loss < best_valid_loss:\n        best_valid_loss = valid_loss\n        torch.save(model.state_dict(), filepath + \"model.pth\")\n    print(f\"\\tTrain Loss: {train_loss:7.3f} | Train PPL: {np.exp(train_loss):7.3f}\")\n    print(f\"\\tValid Loss: {valid_loss:7.3f} | Valid PPL: {np.exp(valid_loss):7.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T05:19:10.735852Z","iopub.execute_input":"2025-04-02T05:19:10.736188Z","iopub.status.idle":"2025-04-02T06:37:36.734963Z","shell.execute_reply.started":"2025-04-02T05:19:10.736087Z","shell.execute_reply":"2025-04-02T06:37:36.734227Z"}},"outputs":[{"name":"stderr","text":"  0%|          | 0/3 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"0 % 1 % 2 % 3 % 4 % 5 % 6 % 7 % 8 % 9 % 10 % \n","output_type":"stream"},{"name":"stderr","text":" 33%|███▎      | 1/3 [26:08<52:16, 1568.27s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   1.859 | Train PPL:   6.419\n\tValid Loss:   1.025 | Valid PPL:   2.788\n0 % 1 % 2 % 3 % 4 % 5 % 6 % 7 % 8 % 9 % 10 % \n","output_type":"stream"},{"name":"stderr","text":" 67%|██████▋   | 2/3 [52:20<26:10, 1570.66s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.908 | Train PPL:   2.479\n\tValid Loss:   0.760 | Valid PPL:   2.139\n0 % 1 % 2 % 3 % 4 % 5 % 6 % 7 % 8 % 9 % 10 % \n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3/3 [1:18:25<00:00, 1568.66s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.677 | Train PPL:   1.969\n\tValid Loss:   0.669 | Valid PPL:   1.953\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"filepath = '/kaggle/working/'\ntorch.save(model.state_dict(), filepath + \"model.pt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T06:37:36.735912Z","iopub.execute_input":"2025-04-02T06:37:36.736262Z","iopub.status.idle":"2025-04-02T06:37:37.271637Z","shell.execute_reply.started":"2025-04-02T06:37:36.736230Z","shell.execute_reply":"2025-04-02T06:37:37.270621Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"filepath = '/kaggle/working/'\nmodel.load_state_dict(torch.load(filepath + \"model.pt\", map_location = device))\nmodel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T06:37:37.272949Z","iopub.execute_input":"2025-04-02T06:37:37.273352Z","iopub.status.idle":"2025-04-02T06:37:37.427501Z","shell.execute_reply.started":"2025-04-02T06:37:37.273314Z","shell.execute_reply":"2025-04-02T06:37:37.426634Z"}},"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"DataParallel(\n  (module): Transformer(\n    (positional_encoding): PositionalEncoding(\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder_embedding): Embedding(19294, 512)\n    (decoder_embedding): Embedding(6594, 512)\n    (encoders): ModuleList(\n      (0-5): 6 x EncoderBlock(\n        (attention): MultiHeadAttention(\n          (W_q): Linear(in_features=512, out_features=512, bias=False)\n          (W_k): Linear(in_features=512, out_features=512, bias=False)\n          (W_v): Linear(in_features=512, out_features=512, bias=False)\n          (W_o): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (feed_forward_network): PositionWiseFeedForwardNetwork(\n          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n          (relu): ReLU()\n        )\n        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n    )\n    (decoders): ModuleList(\n      (0-5): 6 x DecoderBlock(\n        (attention): MultiHeadAttention(\n          (W_q): Linear(in_features=512, out_features=512, bias=False)\n          (W_k): Linear(in_features=512, out_features=512, bias=False)\n          (W_v): Linear(in_features=512, out_features=512, bias=False)\n          (W_o): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (feed_forward_network): PositionWiseFeedForwardNetwork(\n          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n          (relu): ReLU()\n        )\n        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n    )\n    (dropout): Dropout(p=0.1, inplace=False)\n    (fc): Linear(in_features=512, out_features=6594, bias=True)\n  )\n)"},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"test_loss = evaluate_fn(model, test_data_loader, criterion, device)\nprint(f\"\\tTest Loss: {test_loss:7.3f} | Train PPL: {np.exp(test_loss):7.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T06:37:37.428365Z","iopub.execute_input":"2025-04-02T06:37:37.428596Z","iopub.status.idle":"2025-04-02T06:38:48.303198Z","shell.execute_reply.started":"2025-04-02T06:37:37.428578Z","shell.execute_reply":"2025-04-02T06:38:48.302447Z"}},"outputs":[{"name":"stdout","text":"\tTest Loss:   0.671 | Train PPL:   1.957\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"# identifies which positions in the input sentence are padding tokens\ndef get_pad_mask(sentence, pad_idx):\n    mask = (sentence != pad_idx).unsqueeze(1).int().to(device)\n    return mask\n\n#prevent the decoder from attending to future \ndef get_no_peak_mask(sentence):\n    sentence_len = sentence.shape[1]\n    no_peak_mask = 1 - torch.triu(torch.ones((1, sentence_len, sentence_len)), diagonal=1).type(torch.int).to(device)\n    return no_peak_mask ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T06:38:48.303854Z","iopub.execute_input":"2025-04-02T06:38:48.304068Z","iopub.status.idle":"2025-04-02T06:38:48.308741Z","shell.execute_reply.started":"2025-04-02T06:38:48.304050Z","shell.execute_reply":"2025-04-02T06:38:48.308007Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"import torch.nn.functional as F\n\n#Perform greedy decoding using a trained Transformer model.\ndef greedy_decode(model, sentence, max_len = 100):\n    model.eval()\n    \n    input_tokens = token_transform['en'](sentence)\n\n    input_ids = [SOS_IDX] + vocab['en'].lookup_indices(input_tokens) + [EOS_IDX]\n\n    input_tensor = torch.tensor(input_ids).unsqueeze(0).to(device)\n\n    input_mask = get_pad_mask(input_tensor, PAD_IDX)\n    \n    with torch.no_grad():\n        input_embedding = model.module.encoder_embedding(input_tensor)\n        input_embedding = model.module.positional_encoding(input_embedding)\n        encoder_output = input_embedding\n\n        #SELF ATTENTION,FFN AND ADD & NORM\n        for encoder_layer in model.module.encoders:\n            encoder_output = encoder_layer(encoder_output, input_mask)\n            \n    output_ids = [SOS_IDX]\n\n    for i in range(max_len):\n        output_tensor = torch.tensor(output_ids).unsqueeze(0).to(device)\n        output_mask = get_pad_mask(output_tensor, PAD_IDX) & get_no_peak_mask(output_tensor)\n        with torch.no_grad():\n            output_embedding = model.module.decoder_embedding(output_tensor)\n            output_embedding = model.module.positional_encoding(output_embedding)\n            decoder_output = output_embedding\n\n            for decoder_layer in model.module.decoders:\n                decoder_output = decoder_layer(decoder_output, encoder_output, input_mask, output_mask)\n            output = model.module.fc(decoder_output)\n            \n        output = F.softmax(output, dim = -1) \n        #elect the token with the highest probability using argmax().\n        output_id = output.argmax(dim = -1)[:, -1].item()\n        output_ids.append(output_id)\n\n# The End of Sentence (EOS) token is generated.\n        if len(output_ids) > max_len or output_id == EOS_IDX:\n            break\n    \n    output_tokens = [vocab['vi'].get_itos()[idx] for idx in output_ids]\n    return output_tokens ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T06:38:48.309642Z","iopub.execute_input":"2025-04-02T06:38:48.309980Z","iopub.status.idle":"2025-04-02T06:38:48.330061Z","shell.execute_reply.started":"2025-04-02T06:38:48.309945Z","shell.execute_reply":"2025-04-02T06:38:48.329382Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"text = 'i am studying artificial intelligence'\nprint(' '.join(greedy_decode(model, text, 500)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T06:38:48.330905Z","iopub.execute_input":"2025-04-02T06:38:48.331151Z","iopub.status.idle":"2025-04-02T06:38:48.417672Z","shell.execute_reply.started":"2025-04-02T06:38:48.331121Z","shell.execute_reply":"2025-04-02T06:38:48.417058Z"}},"outputs":[{"name":"stdout","text":"<sos> tôi đang học thông minh <eos>\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"translations = [greedy_decode(model, example['en'].lower()) for example in test_data]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T06:38:48.418470Z","iopub.execute_input":"2025-04-02T06:38:48.418771Z","iopub.status.idle":"2025-04-02T07:14:26.916670Z","shell.execute_reply.started":"2025-04-02T06:38:48.418740Z","shell.execute_reply":"2025-04-02T07:14:26.915702Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"references = [example['vi_tokens'] for example in test_data]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T07:14:26.917667Z","iopub.execute_input":"2025-04-02T07:14:26.917910Z","iopub.status.idle":"2025-04-02T07:14:29.094877Z","shell.execute_reply.started":"2025-04-02T07:14:26.917889Z","shell.execute_reply":"2025-04-02T07:14:29.094186Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"print(references[0])\nprint(translations[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T07:14:29.095692Z","iopub.execute_input":"2025-04-02T07:14:29.095901Z","iopub.status.idle":"2025-04-02T07:14:29.100884Z","shell.execute_reply.started":"2025-04-02T07:14:29.095883Z","shell.execute_reply":"2025-04-02T07:14:29.100157Z"}},"outputs":[{"name":"stdout","text":"['<sos>', 'bạn', 'chỉ', 'nên', 'nói', 'chuyện', 'với', 'tom', '.', '<eos>']\n['<sos>', 'bạn', 'chỉ', 'nên', 'nói', 'chuyện', 'với', 'tom', '<eos>']\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"predictions = [example[1:-1] for example in translations]\nreferences = [example[1: -1] for example in references]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T07:14:29.101977Z","iopub.execute_input":"2025-04-02T07:14:29.102311Z","iopub.status.idle":"2025-04-02T07:14:29.154969Z","shell.execute_reply.started":"2025-04-02T07:14:29.102280Z","shell.execute_reply":"2025-04-02T07:14:29.154096Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"references = [[example] for example in references]\nprint(predictions[900])\nprint(references[900])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T07:14:29.155655Z","iopub.execute_input":"2025-04-02T07:14:29.155876Z","iopub.status.idle":"2025-04-02T07:14:29.345201Z","shell.execute_reply.started":"2025-04-02T07:14:29.155857Z","shell.execute_reply":"2025-04-02T07:14:29.344243Z"}},"outputs":[{"name":"stdout","text":"['tôi', 'sẽ', 'không', 'bỏ', 'lỡ', 'nó', 'vì', 'bất', 'cứ', 'điều', 'gì', '.']\n[['tôi', 'sẽ', 'không', 'bỏ', 'lỡ', 'nó', 'cho', 'bất', 'cứ', 'điều', 'gì', '.']]\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"from torchtext.data.metrics import bleu_score\n\n# focusing on the overlap of n-grams (sequences of words).\nscore = bleu_score(predictions, references)\nprint(score)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T07:14:29.345984Z","iopub.execute_input":"2025-04-02T07:14:29.346243Z","iopub.status.idle":"2025-04-02T07:14:37.605637Z","shell.execute_reply.started":"2025-04-02T07:14:29.346221Z","shell.execute_reply":"2025-04-02T07:14:37.604765Z"}},"outputs":[{"name":"stdout","text":"0.6441022563551347\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}